{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from jcopml.pipeline import num_pipe, cat_pipe\n",
    "from jcopml.feature_importance import mean_score_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumlah Baris dan Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat Kembali Jumlah Baris dan Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengubah value dari kolom Cuaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cuaca\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan Regex untuk mengelompokkan jenis Cuaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cuaca(x):\n",
    "  if (re.findall(\"Cerah\", x)):\n",
    "    return 'Cerah'\n",
    "  elif (re.findall(\"Hujan\", x)):\n",
    "    return 'Hujan'\n",
    "  elif (re.findall(\"Berawan\", x)):\n",
    "    return 'Berawan'\n",
    "  else:\n",
    "    return 'Tidak Teridentifikasi'\n",
    "\n",
    "df[\"cuaca\"] = df['cuaca'].apply(cuaca)\n",
    "df[\"cuaca\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.waktu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cuaca(x):\n",
    "  if (re.findall(\"dini hari\", x)):\n",
    "    return 'Dini Hari'\n",
    "  elif (re.findall(\"siang\", x)):\n",
    "    return 'Siang'\n",
    "  elif (re.findall(\"pagi\", x)):\n",
    "    return 'Pagi'\n",
    "  elif (re.findall(\"malam\", x)):\n",
    "    return 'Malam'\n",
    "  else:\n",
    "    return x\n",
    "\n",
    "df[\"waktu\"] = df['waktu'].apply(cuaca)\n",
    "df[\"waktu\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"cuaca\"] == \"Tidak Teridentifikasi\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"cuaca\"] == \"Tidak Teridentifikasi\"].index, inplace=True)\n",
    "df[\"cuaca\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data Kelembaban menjadi Kelembapan Minimal dan Maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kelembapan_min\"] = df['kelembaban_persen'].apply(lambda x: x.split(\"-\")[0])\n",
    "df[\"kelembapan_min\"] = [x.strip(' ') for x in df[\"kelembapan_min\"]]\n",
    "\n",
    "df[\"kelembapan_max\"] = df['kelembaban_persen'].apply(lambda x: x.split(\"-\")[1])\n",
    "df[\"kelembapan_max\"] = [x.strip(' ') for x in df[\"kelembapan_max\"]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"suhu_min\"] = df.suhu_derajat_celcius.apply(lambda x: x.split(\"-\")[0])\n",
    "df[\"suhu_min\"] = [x.strip(' ') for x in df[\"suhu_min\"]]\n",
    "\n",
    "df[\"suhu_max\"] = df.suhu_derajat_celcius.apply(lambda x: x.split(\"-\")[1])\n",
    "df[\"suhu_max\"] = [x.strip(' ') for x in df[\"suhu_max\"]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melihat Masing Masing Data dari Suhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Suhu Min\\n', df['suhu_min'].value_counts(), '\\n')\n",
    "print('Suhu Max\\n', df['suhu_max'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melihat Masing Masing Data dari Kelembapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kelembapan Min\\n', df['kelembapan_min'].value_counts(), '\\n\\n')\n",
    "print('Kelembapan Min\\n', df['kelembapan_max'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap Praprocessing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"kelembaban_persen\", \"suhu_derajat_celcius\", \"tanggal\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wilayah.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengubah Tipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kelembapan_min\"] = df.kelembapan_min.astype(int)\n",
    "df[\"kelembapan_max\"] = df.kelembapan_max.astype(int)\n",
    "df[\"suhu_min\"] = df.suhu_min.astype(int)\n",
    "df[\"suhu_max\"] = df.suhu_max.astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"cuaca\", corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"cuaca\"] = le.fit_transform(df['cuaca'])\n",
    "df['cuaca'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Kolom Rata Rata untuk Suhu dan Kelembapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kelembapan_mean'] = (df['kelembapan_min'] + df['kelembapan_max']) / 2\n",
    "df['suhu_mean'] = (df['suhu_min'] + df['suhu_max']) / 2\n",
    "\n",
    "df.drop(columns=[\"kelembapan_min\", \"kelembapan_max\", \"suhu_min\", 'suhu_max'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"cuaca\"])\n",
    "y = df[\"cuaca\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap Preprocessing 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=[\"waktu\", \"wilayah\"])\n",
    "X_test = pd.get_dummies(X_test, columns=[\"waktu\", \"wilayah\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi Data menggunakan Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "numeric = [\"kelembapan_mean\", \"suhu_mean\"]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train[numeric] = scaler.fit_transform(X_train[numeric])\n",
    "X_test[numeric] = scaler.fit_transform(X_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramater = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [20, 50, 80],\n",
    "    'max_features': [0.3, 0.6, 0.8],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "RF = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "model = GridSearchCV(RF, paramater, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 67% <br>\n",
    "Akurasi Testing 63% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramater = {\n",
    "    'gamma': [1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03],\n",
    "    'C': [1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "SVM = SVC(max_iter=1000, random_state=42)\n",
    "\n",
    "model = GridSearchCV(SVM, paramater, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 57% <br>\n",
    "Akurasi Testing 56% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramater = {\n",
    "    'solver': ['adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'hidden_layer_sizes': [(9,8), (9,9), (7,9), (6,9), (7,8), (8,9)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "MLPC = MLPClassifier(max_iter=5000, random_state=42)\n",
    "\n",
    "model = GridSearchCV(MLPC, paramater, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 63% <br>\n",
    "Akurasi Testing 62% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramater = {\n",
    "    'n_neighbors': [1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 1.5, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "model = GridSearchCV(KNN, paramater, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 65% <br>\n",
    "Akurasi Testing 61% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramater = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "model = GridSearchCV(DTC, paramater, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 65% <br>\n",
    "Akurasi Testing 62% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jcopml.tuning.space import Integer, Real\n",
    "\n",
    "parameter = {\n",
    "    'max_depth': Integer(low=1, high=10),\n",
    "    'learning_rate': Real(low=-2, high=0, prior='log-uniform'),\n",
    "    'n_estimators': Integer(low=100, high=200),\n",
    "    'subsample': Real(low=0.3, high=0.8, prior='uniform'),\n",
    "    'gamma': Integer(low=1, high=10),\n",
    "    'colsample_bytree': Real(low=0.1, high=1, prior='uniform'),\n",
    "    'reg_alpha': Real(low=-3, high=1, prior='log-uniform'),\n",
    "    'reg_lambda': Real(low=-3, high=1, prior='log-uniform')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "XGB = XGBClassifier(n_jobs=-1, random_state=42, use_label_encoder=False)\n",
    "\n",
    "model = RandomizedSearchCV(XGB, parameter, cv=3, n_iter=500, n_jobs=-1, verbose=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_train, y_pred_train), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi Training 66% <br>\n",
    "Akurasi Testing 64% <br>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4eaf1be304415beee96765ae99c3f893cc8312c7f1196698e6029668e9aeb3e5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
